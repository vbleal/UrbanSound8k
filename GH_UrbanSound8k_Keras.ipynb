{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOkYw8Ygn7bawIIme7GS8Ul"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **UrbanSound8K con Keras**"],"metadata":{"id":"Yqa4xxNRYh77"}},{"cell_type":"markdown","source":["Creado por:\n","\n","* **V. D. Betancourt**"],"metadata":{"id":"fLErv6-krdR0"}},{"cell_type":"markdown","source":["## Intro UrbanSound8K"],"metadata":{"id":"tF3d9BkulOcU"}},{"cell_type":"markdown","source":["\n","-  **DESCRIPCIÓN**\n","\n","Este conjunto de datos contiene 8732 fragmentos de sonidos urbanos etiquetados (<=4s) de 10 clases: aire acondicionado, bocina de carro, niños jugando, ladrido de perro, taladrado, ralentí del motor, disparo de arma, martillo neumático, sirena y música callejera. Las clases provienen de la taxonomía de sonidos urbanos.\n","\n","Todos los fragmentos provienen de grabaciones de campo subidas a www.freesound.org. Los archivos están pre-organizados en diez grupos (carpetas nombradas de fold1 a fold10) para ayudar en la reproducción y comparación con los resultados de clasificación automática reportados en el artículo mencionado.\n","\n","Además de los fragmentos de sonido, también se proporciona un archivo CSV que contiene metadatos sobre cada fragmento.\n","\n"],"metadata":{"id":"N9YNogsvZbMH"}},{"cell_type":"markdown","source":["-  **ARCHIVOS DE AUDIO INCLUIDOS**\n","\n","8732 archivos de audio de sonidos urbanos (ver descripción arriba) en formato WAV. La tasa de muestreo, profundidad de bits y número de canales son los mismos que los del archivo original subido a Freesound (y por lo tanto pueden variar de archivo a archivo).\n","\n"],"metadata":{"id":"v5bx3YYZrK22"}},{"cell_type":"markdown","source":["-  **ARCHIVOS DE META-DATOS INCLUIDOS**\n","\n","  **`UrbanSound8k.csv`**\n","\n","  -  **Column Names**\n","\n","    -  **`slice_file_name`**: The name of the audio file. The name takes the following format: [fsID]-[classID]-[occurrenceID]-[sliceID].wav, where: [fsID] = the Freesound ID of the recording from which this excerpt (slice) is taken [classID] = a numeric identifier of the sound class (see description of classID below for further details) [occurrenceID] = a numeric identifier to distinguish different occurrences of the sound within the original recording [sliceID] = a numeric identifier to distinguish different slices taken from the same occurrence\n","\n","    -  **`fsID`**: The Freesound ID of the recording from which this excerpt (slice) is taken\n","\n","    -  **`start`**: The start time of the slice in the original Freesound recording\n","\n","    -  **`end`**: The end time of slice in the original Freesound recording\n","\n","    -  **`salience`**: A (subjective) salience rating of the sound. 1 = foreground, 2 = background.\n","\n","    -  **`fold`**: The fold number (1-10) to which this file has been allocated.\n","\n","    -  **`classID`**: A numeric identifier of the sound class: 0 = air_conditioner 1 = car_horn 2 = children_playing 3 = dog_bark 4 = drilling 5 = engine_idling 6 = gun_shot 7 = jackhammer 8 = siren 9 = street_music\n","\n","    -  **`class`**: The class name: air_conditioner, car_horn, children_playing, dog_bark, drilling, engine_idling, gun_shot, jackhammer, siren, street_music."],"metadata":{"id":"sKDdOwWUrQCj"}},{"cell_type":"markdown","source":["-  **RECOMENDACIONES específicas de UrbanSound8K**\n","\n","  1. **¡No reorganices los datos!** Usa los 10 grupos predefinidos y realiza validación cruzada de 10 pliegues (no de 5 pliegues).\n","\n","    Los experimentos realizados por la gran mayoría de publicaciones que usan UrbanSound8K (por nosotros y otros) evalúan los modelos de clasificación mediante validación cruzada de 10 pliegues usando las divisiones predefinidas*. Recomendamos encarecidamente seguir este procedimiento.\n","\n","    - ¿Por qué?\n","\n","      Si reorganizas los datos (por ejemplo, combinando los datos de todos los grupos y generando una división aleatoria de entrenamiento/prueba) estarás colocando incorrectamente muestras relacionadas tanto en los conjuntos de entrenamiento como de prueba, lo que lleva a puntajes inflados que no representan el rendimiento de tu modelo en datos no vistos. En pocas palabras, tus resultados serán incorrectos. Tus resultados NO serán comparables con resultados anteriores en la literatura, lo que significa que cualquier afirmación de una mejora sobre investigaciones anteriores será inválida. Incluso si no reorganizas los datos, evaluar usando divisiones diferentes (por ejemplo, validación cruzada de 5 pliegues) significará que tus resultados no son comparables con investigaciones anteriores.\n","\n","\n","\n","  2. **¡No evalúes solo en una división!** Usa validación cruzada de 10 pliegues (no de 5 pliegues) y promedia los puntajes.\n","\n","    Hemos visto informes que solo proporcionan resultados para una única división de entrenamiento/prueba, por ejemplo, entrenar en los grupos 1-9, probar en el grupo 10 y reportar un único puntaje de precisión. Aconsejamos en contra de esto. En su lugar, realiza validación cruzada de 10 pliegues usando los grupos proporcionados e informa el puntaje promedio.\n","\n","    - ¿Por qué?\n","\n","      No todos los grupos son tan \"fáciles\". Es decir, los modelos tienden a obtener puntajes mucho más altos cuando se entrenan en los grupos 1-9 y se prueban en el grupo 10, comparado con (por ejemplo) entrenar en los grupos 2-10 y probar en el grupo 1. Por esta razón, es importante evaluar tu modelo en cada una de las 10 divisiones e informar la precisión promedio. De nuevo, tus resultados no serán comparables con resultados anteriores en la literatura."],"metadata":{"id":"ylQCdUhBqS5W"}},{"cell_type":"markdown","source":["."],"metadata":{"id":"KIupgQX4pZZI"}},{"cell_type":"markdown","source":["## Intro Artículo: **End-to-End Environmental Sound Classification using a 1D Convolutional Neural Network**"],"metadata":{"id":"WTTH95KxZbhT"}},{"cell_type":"markdown","source":["\n","Autores: **Sajjad Abdoli, Patrick Cardinal, Alessandro Lameiras Koerich**"],"metadata":{"id":"m03k5vDLlUfC"}},{"cell_type":"markdown","source":["Este artículo describe un método para clasificar sonidos ambientales usando una Red Neuronal Convolucional (CNN) de 1 dimensión.\n","\n","Este método aprende directamente del audio, usando varias capas convolucionales para capturar detalles finos del tiempo en el sonido y aprender filtros diversos que ayudan en la tarea de clasificación. Puede manejar señales de audio de cualquier longitud, dividiéndolas en segmentos superpuestos mediante una ventana deslizante.\n","\n","Se evaluaron diferentes estructuras, incluida una que inicia con un banco de filtros **Gammatone**, que imita cómo el oído humano procesa los sonidos en la cóclea.\n","\n","El método se probó con el conjunto de datos **UrbanSound8k**, alcanzando un 89% de precisión media, superando a la mayoría de los métodos actuales que utilizan características diseñadas manualmente o representaciones en 2D. Además, este enfoque requiere menos parámetros que otros métodos, lo que significa que necesita menos datos para el entrenamiento."],"metadata":{"id":"rQLVqYTnmpEY"}},{"cell_type":"markdown","source":["."],"metadata":{"id":"Y5M4UPgVUWq5"}},{"cell_type":"markdown","source":["## **Preprocessing**"],"metadata":{"id":"ga8QNbp6RvKw"}},{"cell_type":"markdown","source":["* **Dataset UrbanSound8k**: Utilizado para la evaluación de modelos con 8,732 clips de audio a diferentes tasas de muestreo, reducidos a 16 kHz.\n","\n","* **Segmentación de Audio**: Archivos de audio segmentados en 16,000 muestras con marcos superpuestos en un 50%. Esto podría replicarse mediante el preprocesamiento de datos de audio para ajustarse a los requisitos de entrada del modelo."],"metadata":{"id":"1hd0HmZHR8jq"}},{"cell_type":"markdown","source":["."],"metadata":{"id":"U3BkBNcXUXmm"}},{"cell_type":"markdown","source":["## **Arquitectura y Training**"],"metadata":{"id":"20VALWONRslF"}},{"cell_type":"markdown","source":["* **Capas Convolucionales**: La experimentación mostró un aumento en la precisión con más capas convolucionales hasta cuatro, después de lo cual la dimensión del mapa de características se minimiza. Esto sugiere que un modelo con hasta cuatro capas convolucionales es óptimo para esta tarea.\n","\n","* **Evaluación en Diferentes Longitudes de Audio**: El modelo se adaptó para varios tamaños de entrada, logrando la mayor precisión con entradas de 16,000 muestras. Esto enfatiza la importancia de considerar la longitud de entrada en el diseño de la arquitectura del modelo."],"metadata":{"id":"Z2lJIz4vSD3F"}},{"cell_type":"markdown","source":["."],"metadata":{"id":"23nKROToUY1L"}},{"cell_type":"markdown","source":["## **Fine-Tuning y Mejoras**"],"metadata":{"id":"UXNbnC4MSQpl"}},{"cell_type":"markdown","source":["* **Solapamiento de Ventanas y Tamaño de Marco**: Se probaron diferentes configuraciones de solapamiento de ventanas y tamaños de marcos de audio, resaltando la importancia de estos parámetros en el rendimiento del modelo.\n","\n","* **Mejoras en la Arquitectura**:\n","\n","  - Reemplazar la ventana deslizante de Hamming por una rectangular para una posible mejora en la precisión.\n","\n","  - Aumentar el solapamiento de ventanas durante la segmentación de audio puede mejorar el rendimiento.\n","\n","  - Inicializar la primera capa convolucional con un banco de filtros Gammatone y hacerla no entrenable para mejorar la precisión."],"metadata":{"id":"lERppcPLSUg8"}},{"cell_type":"markdown","source":["."],"metadata":{"id":"GkV-NwwyUa2A"}},{"cell_type":"markdown","source":["## **Optimización**"],"metadata":{"id":"gUeW1yv1SltF"}},{"cell_type":"markdown","source":["* **Optimización**: Se utilizó el optimizador Adadelta con una tasa de aprendizaje predeterminada de 1.0, adaptando dinámicamente la tasa de aprendizaje durante la optimización.\n","\n","* **Agregación de Predicciones al Estilo de Conjunto**: Combinar predicciones de marcos de audio segmentados puede mejorar el rendimiento general de la clasificación.\n","\n"],"metadata":{"id":"js6uCcdnSo8a"}},{"cell_type":"markdown","source":["."],"metadata":{"id":"dGApGkFSUcGv"}},{"cell_type":"markdown","source":["## **Conclusiones**"],"metadata":{"id":"eD-A5CHxWQ5Y"}},{"cell_type":"markdown","source":["* **Eficiencia de la Arquitectura**: La CNN 1D propuesta, con tres a cinco capas convolucionales, aprende de manera eficiente representaciones de filtros directamente de la forma de onda de audio, superando a las CNNs 2D de última generación utilizadas para la clasificación de sonidos ambientales en términos de precisión y complejidad del modelo.\n","\n","* **Reducción de la Complejidad del Modelo**: A pesar de tener menos parámetros que muchas arquitecturas de CNN 2D, la CNN 1D logra una precisión media significativamente mayor, mostrando la eficiencia y efectividad del modelo.\n","\n","* **Potencial para la Integración de Representaciones 1D y 2D**: La observación de que puede haber aspectos complementarios entre los filtros 1D (aprendidos directamente de las formas de onda de audio) y los filtros 2D (aprendidos de los espectrogramas) sugiere una dirección futura de investigación. Integrar representaciones 1D y 2D podría potencialmente mejorar el rendimiento de clasificación para ciertas clases de sonido.\n","\n","* **Necesidad de más Investigación**: El artículo indica la necesidad de investigar más sobre los filtros ruidosos de las capas convolucionales intermedias sin frecuencias dominantes. Esto apunta a posibles mejoras en el modelo al refinar estos filtros."],"metadata":{"id":"jkGMQcIvWSzy"}},{"cell_type":"markdown","source":["## **Código Python-Keras**"],"metadata":{"id":"nSGrSDNWSv1Z"}},{"cell_type":"code","source":["# Arquitectura / Modelo Red Neuronal con Keras\n","from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Activation\n","from keras.optimizers import Adadelta\n","\n","model = Sequential()\n","\n","# Suponiendo que se ha inicializado Gammatone de forma independiente\n","\n","# Primera capa convolucional\n","model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(16000, 1)))\n","model.add(MaxPooling1D(2))\n","\n","# Segunda capa convolucional\n","model.add(Conv1D(128, kernel_size=3, activation='relu'))\n","model.add(MaxPooling1D(2))\n","\n","# Tercera capa convolucional\n","model.add(Conv1D(256, kernel_size=3, activation='relu'))\n","model.add(MaxPooling1D(2))\n","\n","# Cuarta capa convolucional\n","model.add(Conv1D(512, kernel_size=3, activation='relu'))\n","model.add(MaxPooling1D(2))\n","\n","# Aplanamiento\n","model.add(Flatten())\n","\n","# Capas densas (para clasificación) completamente conectadas con Dropout\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.25))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.25))\n","model.add(Dense(10, activation='softmax'))  # 10 classes de UrbanSound8k\n","\n","# Optimizador Adadelta con Tasa de Aprendizaje de 1.0\n","optimizer = Adadelta(learning_rate=1.0)\n","\n","# Compilar el modelo\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","model.summary()"],"metadata":{"id":"RUyC5zqaSvNg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712101483759,"user_tz":360,"elapsed":11147,"user":{"displayName":"Vic D. Betancourt","userId":"11556856888181703399"}},"outputId":"a4558e4b-6f9f-42aa-a7cd-34a2b7899056"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 15998, 64)         256       \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 7999, 64)          0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 7997, 128)         24704     \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 3998, 128)         0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 3996, 256)         98560     \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 1998, 256)         0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1996, 512)         393728    \n","                                                                 \n"," max_pooling1d_3 (MaxPoolin  (None, 998, 512)          0         \n"," g1D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 510976)            0         \n","                                                                 \n"," dense (Dense)               (None, 128)               65405056  \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dropout_1 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 65931210 (251.51 MB)\n","Trainable params: 65931210 (251.51 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]}]}