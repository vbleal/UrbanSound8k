# UrbanSound8k

>Python, Convolutional Neural Networks, UrbanSound8k, FreeSound

Paper:

* Sajjad Abdoli; Patrick Cardinal; Alessandro Lameiras Koerich (2019). ***End-to-End Environmental Sound Classification using a 1D Convolutional Neural Network.*** arXiv: [https://doi.org/10.48550/arXiv.1904.08990](https://doi.org/10.48550/arXiv.1904.08990)


Creado por:

- **V. D. Betancourt**




## üìë **Sobre el Art√≠culo**

<details>
    <summary> Expandir </summary>

Este art√≠culo describe un m√©todo para clasificar sonidos ambientales usando una Red Neuronal Convolucional (CNN) de 1 dimensi√≥n (1D).
Este m√©todo aprende directamente del audio, usando varias capas convolucionales para capturar detalles finos del tiempo en el sonido y aprender filtros diversos que ayudan en la tarea de clasificaci√≥n. Puede manejar se√±ales de audio de cualquier longitud, dividi√©ndolas en segmentos superpuestos mediante una ventana deslizante.
Se evaluaron diferentes estructuras, incluida una que inicia con un banco de filtros Gammatone, que imita c√≥mo el o√≠do humano procesa los sonidos en la c√≥clea.
El m√©todo se prob√≥ con el dataset UrbanSound8k, alcanzando un 89% de precisi√≥n media, superando a la mayor√≠a de los m√©todos actuales que utilizan caracter√≠sticas dise√±adas manualmente o representaciones en 2D. Adem√°s, este enfoque requiere menos par√°metros que otros m√©todos, lo que significa que necesita menos datos para el entrenamiento.



</details>

----------------




## üí° **Sobre el Dataset: UrbanSound8K**

<details>
    <summary> Expandir </summary>


### Descripci√≥n

Este conjunto de datos contiene 8732 fragmentos de sonidos urbanos etiquetados (<=4s) de 10 clases: aire acondicionado, bocina de carro, ni√±os jugando, ladrido de perro, taladrado, ralent√≠ del motor, disparo de arma, martillo neum√°tico, sirena y m√∫sica callejera. Las clases provienen de la taxonom√≠a de sonidos urbanos.
Todos los fragmentos provienen de grabaciones de campo subidas a www.freesound.org. Los archivos est√°n pre-organizados en diez grupos (carpetas nombradas de fold1 a fold10) para ayudar en la reproducci√≥n y comparaci√≥n con los resultados de clasificaci√≥n autom√°tica reportados en el art√≠culo mencionado.

Adem√°s de los fragmentos de sonido, tambi√©n se proporciona un archivo CSV que contiene metadatos sobre cada fragmento.



### Archivos de Audio Incluidos

8732 archivos de audio de sonidos urbanos (ver descripci√≥n arriba) en formato WAV. La tasa de muestreo, profundidad de bits y n√∫mero de canales son los mismos que los del archivo original subido a Freesound (y por lo tanto pueden variar de archivo a archivo).


### Archivos de Meta-Datos Incluidos

Metadata: UrbanSound8k.csv

Columnas:

*	**slice_file_name**: El nombre del archivo de audio. El nombre sigue el siguiente formato: [fsID]-[classID]-[occurrenceID]-[sliceID].wav, donde: [fsID] = el ID de Freesound de la grabaci√≥n de la cual se ha tomado este fragmento (slice) [classID] = un identificador num√©rico de la clase de sonido (ver descripci√≥n de classID abajo para m√°s detalles) [occurrenceID] = un identificador num√©rico para distinguir diferentes ocurrencias del sonido dentro de la grabaci√≥n original [sliceID] = un identificador num√©rico para distinguir diferentes fragmentos tomados de la misma ocurrencia.

* **fsID**: El ID de Freesound de la grabaci√≥n de la cual se ha tomado este fragmento (slice).

*	**start**: El tiempo de inicio del fragmento en la grabaci√≥n original de Freesound.

*	**end**: El tiempo de fin del fragmento en la grabaci√≥n original de Freesound.

*	**salience**: Una calificaci√≥n de saliencia (subjetiva) del sonido. 1 = primer plano, 2 = fondo.

*	**fold**: El n√∫mero de grupo (1-10) al cual ha sido asignado este archivo.

*	**classID**: Un identificador num√©rico de la clase de sonido: 0 = air_conditioner 1 = car_horn 2 = children_playing 3 = dog_bark 4 = drilling 5 = engine_idling 6 = gun_shot 7 = jackhammer 8 = siren 9 = street_music.

*	**class**: El nombre de la clase: air_conditioner, car_horn, children_playing, dog_bark, drilling, engine_idling, gun_shot, jackhammer, siren, street_music.





### Recomendaciones de UrbanSound8K

1.	**¬°No reorganices los datos! Usa los 10 pliegues (folds) predefinidos y realiza validaci√≥n cruzada de 10 pliegues (no de 5 pliegues).**

    Los experimentos realizados por la gran mayor√≠a de publicaciones que usan UrbanSound8K, eval√∫an los modelos de clasificaci√≥n mediante validaci√≥n cruzada de 10 pliegues usando las divisiones predefinidas. Recomendamos encarecidamente seguir este procedimiento.
  
  * **¬øPor qu√©?**

    - Si reorganizas los datos (por ejemplo, combinando los datos de todos los grupos y generando una divisi√≥n aleatoria de entrenamiento/prueba) estar√°s colocando   incorrectamente muestras relacionadas tanto en los conjuntos de entrenamiento como de prueba, lo que lleva a puntajes inflados que no representan el rendimiento de tu modelo en datos no vistos. En pocas palabras, tus resultados ser√°n incorrectos. Tus resultados no ser√°n comparables con resultados anteriores en la literatura, lo que significa que cualquier afirmaci√≥n de una mejora sobre investigaciones anteriores ser√° inv√°lida. Incluso si no reorganizas los datos, evaluar usando divisiones diferentes (por ejemplo, validaci√≥n cruzada de 5 pliegues) significar√° que tus resultados no son comparables con investigaciones anteriores.

2.	**¬°No eval√∫es solo en una divisi√≥n! Usa validaci√≥n cruzada de 10 pliegues (folds) (no de 5 pliegues) y promedia los puntajes.**

    Se han visto informes que solo proporcionan resultados para una √∫nica divisi√≥n de entrenamiento/prueba, por ejemplo, entrenar en los grupos 1-9, probar en el grupo 10 y reportar un √∫nico puntaje de precisi√≥n. Aconsejamos en contra de esto. En su lugar, realiza validaci√≥n cruzada de 10 pliegues usando los grupos proporcionados e informa el puntaje promedio.

  * **¬øPor qu√©?**

    - No todos los grupos son tan "f√°ciles". Es decir, los modelos tienden a obtener puntajes mucho m√°s altos cuando se entrenan en los grupos 1-9 y se prueban en el grupo 10, comparado con (por ejemplo) entrenar en los grupos 2-10 y probar en el grupo 1. Por esta raz√≥n, es importante evaluar tu modelo en cada una de las 10 divisiones e informar la precisi√≥n promedio. De nuevo, tus resultados no ser√°n comparables con resultados anteriores en la literatura.




</details>

----------------




## üìä **Pre-Processing**

<details>
    <summary> Expandir </summary>

* **Dataset UrbanSound8k**: Utilizado para la evaluaci√≥n de modelos con 8,732 clips de audio a diferentes tasas de muestreo, reducidos a 16 kHz.

* **Segmentaci√≥n de Audio**: Archivos de audio segmentados en 16,000 muestras con marcos superpuestos en un 50%. Esto podr√≠a replicarse mediante el preprocesamiento de datos de audio para ajustarse a los requisitos de entrada del modelo.


</details>

----------------






##  üß¨ **Arquitectura y Training**

<details>
    <summary> Expandir </summary>

* **Capas Convolucionales**: La experimentaci√≥n mostr√≥ un aumento en la precisi√≥n con m√°s capas convolucionales hasta cuatro, despu√©s de lo cual la dimensi√≥n del mapa de caracter√≠sticas se minimiza. Esto sugiere que un modelo con hasta cuatro capas convolucionales es √≥ptimo para esta tarea.

* **Evaluaci√≥n en Diferentes Longitudes de Audio**: El modelo se adapt√≥ para varios tama√±os de entrada, logrando la mayor precisi√≥n con entradas de 16,000 muestras. Esto enfatiza la importancia de considerar la longitud de entrada en el dise√±o de la arquitectura del modelo.


</details>

----------------




##  üîß **Fine-Tuning y Mejoras**

<details>
    <summary> Expandir </summary>

* **Solapamiento de Ventanas y Tama√±o de Marco**: Se probaron diferentes configuraciones de solapamiento de ventanas y tama√±os de marcos de audio, resaltando la importancia de estos par√°metros en el rendimiento del modelo.

* **Mejoras en la Arquitectura**:

  - Reemplazar la ventana deslizante de Hamming por una rectangular para una posible mejora en la precisi√≥n.

  - Aumentar el solapamiento de ventanas durante la segmentaci√≥n de audio puede mejorar el rendimiento.

  - Inicializar la primera capa convolucional con un banco de filtros Gammatone y hacerla no entrenable para mejorar la precisi√≥n.


</details>

----------------




##  üéöÔ∏è**Optimizaci√≥n**

<details>
    <summary> Expandir </summary>

* **Optimizaci√≥n**: Se utiliz√≥ el optimizador Adadelta con una tasa de aprendizaje predeterminada de 1.0, adaptando din√°micamente la tasa de aprendizaje durante la optimizaci√≥n.

* **Agregaci√≥n de Predicciones al Estilo de Conjunto**: Combinar predicciones de marcos de audio segmentados puede mejorar el rendimiento general de la clasificaci√≥n.



</details>

----------------




## üìú **Conclusiones**

<details>
    <summary> Expandir </summary>

* **Eficiencia de la Arquitectura**: La CNN 1D propuesta, con tres a cinco capas convolucionales, aprende de manera eficiente representaciones de filtros directamente de la forma de onda de audio, superando a las CNNs 2D de √∫ltima generaci√≥n utilizadas para la clasificaci√≥n de sonidos ambientales en t√©rminos de precisi√≥n y complejidad del modelo.

* **Reducci√≥n de la Complejidad del Modelo**: A pesar de tener menos par√°metros que muchas arquitecturas de CNN 2D, la CNN 1D logra una precisi√≥n media significativamente mayor, mostrando la eficiencia y efectividad del modelo.

* **Potencial para la Integraci√≥n de Representaciones 1D y 2D**: La observaci√≥n de que puede haber aspectos complementarios entre los filtros 1D (aprendidos directamente de las formas de onda de audio) y los filtros 2D (aprendidos de los espectrogramas) sugiere una direcci√≥n futura de investigaci√≥n. Integrar representaciones 1D y 2D podr√≠a potencialmente mejorar el rendimiento de clasificaci√≥n para ciertas clases de sonido.

* **Necesidad de m√°s Investigaci√≥n**: El art√≠culo indica la necesidad de investigar m√°s sobre los filtros ruidosos de las capas convolucionales intermedias sin frecuencias dominantes. Esto apunta a posibles mejoras en el modelo al refinar estos filtros.


</details>

----------------




## „äôÔ∏è **C√≥digo**

<details>
    <summary> Expandir </summary>

* [Modelo](https://github.com/vbleal/UrbanSound8k/blob/main/GH_UrbanSound8k_Keras.ipynb)
  

</details>

----------------



