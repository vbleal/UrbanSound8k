# UrbanSound8k

>Python, Convolutional Neural Networks, UrbanSound8k, FreeSound

Paper:

* Sajjad Abdoli; Patrick Cardinal; Alessandro Lameiras Koerich (2019). ***End-to-End Environmental Sound Classification using a 1D Convolutional Neural Network.*** arXiv: [https://doi.org/10.48550/arXiv.1904.08990](https://doi.org/10.48550/arXiv.1904.08990)


Creado por:

- **V. D. Betancourt**




##  **Sobre el Art铆culo**

<details>
    <summary> Expandir </summary>

Este art铆culo describe un m茅todo para clasificar sonidos ambientales usando una Red Neuronal Convolucional (CNN) de 1 dimensi贸n (1D).
Este m茅todo aprende directamente del audio, usando varias capas convolucionales para capturar detalles finos del tiempo en el sonido y aprender filtros diversos que ayudan en la tarea de clasificaci贸n. Puede manejar se帽ales de audio de cualquier longitud, dividi茅ndolas en segmentos superpuestos mediante una ventana deslizante.
Se evaluaron diferentes estructuras, incluida una que inicia con un banco de filtros Gammatone, que imita c贸mo el o铆do humano procesa los sonidos en la c贸clea.
El m茅todo se prob贸 con el dataset UrbanSound8k, alcanzando un 89% de precisi贸n media, superando a la mayor铆a de los m茅todos actuales que utilizan caracter铆sticas dise帽adas manualmente o representaciones en 2D. Adem谩s, este enfoque requiere menos par谩metros que otros m茅todos, lo que significa que necesita menos datos para el entrenamiento.



</details>

----------------




##  **Sobre el Dataset: UrbanSound8K**

<details>
    <summary> Expandir </summary>


### Descripci贸n

Este conjunto de datos contiene 8732 fragmentos de sonidos urbanos etiquetados (<=4s) de 10 clases: aire acondicionado, bocina de carro, ni帽os jugando, ladrido de perro, taladrado, ralent铆 del motor, disparo de arma, martillo neum谩tico, sirena y m煤sica callejera. Las clases provienen de la taxonom铆a de sonidos urbanos.
Todos los fragmentos provienen de grabaciones de campo subidas a www.freesound.org. Los archivos est谩n pre-organizados en diez grupos (carpetas nombradas de fold1 a fold10) para ayudar en la reproducci贸n y comparaci贸n con los resultados de clasificaci贸n autom谩tica reportados en el art铆culo mencionado.

Adem谩s de los fragmentos de sonido, tambi茅n se proporciona un archivo CSV que contiene metadatos sobre cada fragmento.



### Archivos de Audio Incluidos

8732 archivos de audio de sonidos urbanos (ver descripci贸n arriba) en formato WAV. La tasa de muestreo, profundidad de bits y n煤mero de canales son los mismos que los del archivo original subido a Freesound (y por lo tanto pueden variar de archivo a archivo).


### Archivos de Meta-Datos Incluidos

Metadata: UrbanSound8k.csv

Columnas:

*	**slice_file_name**: El nombre del archivo de audio. El nombre sigue el siguiente formato: [fsID]-[classID]-[occurrenceID]-[sliceID].wav, donde: [fsID] = el ID de Freesound de la grabaci贸n de la cual se ha tomado este fragmento (slice) [classID] = un identificador num茅rico de la clase de sonido (ver descripci贸n de classID abajo para m谩s detalles) [occurrenceID] = un identificador num茅rico para distinguir diferentes ocurrencias del sonido dentro de la grabaci贸n original [sliceID] = un identificador num茅rico para distinguir diferentes fragmentos tomados de la misma ocurrencia.

* **fsID**: El ID de Freesound de la grabaci贸n de la cual se ha tomado este fragmento (slice).

*	**start**: El tiempo de inicio del fragmento en la grabaci贸n original de Freesound.

*	**end**: El tiempo de fin del fragmento en la grabaci贸n original de Freesound.

*	**salience**: Una calificaci贸n de saliencia (subjetiva) del sonido. 1 = primer plano, 2 = fondo.

*	**fold**: El n煤mero de grupo (1-10) al cual ha sido asignado este archivo.

*	**classID**: Un identificador num茅rico de la clase de sonido: 0 = air_conditioner 1 = car_horn 2 = children_playing 3 = dog_bark 4 = drilling 5 = engine_idling 6 = gun_shot 7 = jackhammer 8 = siren 9 = street_music.

*	**class**: El nombre de la clase: air_conditioner, car_horn, children_playing, dog_bark, drilling, engine_idling, gun_shot, jackhammer, siren, street_music.





### Recomendaciones de UrbanSound8K

1.	**隆No reorganices los datos! Usa los 10 pliegues (folds) predefinidos y realiza validaci贸n cruzada de 10 pliegues (no de 5 pliegues).**

    Los experimentos realizados por la gran mayor铆a de publicaciones que usan UrbanSound8K, eval煤an los modelos de clasificaci贸n mediante validaci贸n cruzada de 10 pliegues usando las divisiones predefinidas. Recomendamos encarecidamente seguir este procedimiento.
  
  * **驴Por qu茅?**

    - Si reorganizas los datos (por ejemplo, combinando los datos de todos los grupos y generando una divisi贸n aleatoria de entrenamiento/prueba) estar谩s colocando   incorrectamente muestras relacionadas tanto en los conjuntos de entrenamiento como de prueba, lo que lleva a puntajes inflados que no representan el rendimiento de tu modelo en datos no vistos. En pocas palabras, tus resultados ser谩n incorrectos. Tus resultados no ser谩n comparables con resultados anteriores en la literatura, lo que significa que cualquier afirmaci贸n de una mejora sobre investigaciones anteriores ser谩 inv谩lida. Incluso si no reorganizas los datos, evaluar usando divisiones diferentes (por ejemplo, validaci贸n cruzada de 5 pliegues) significar谩 que tus resultados no son comparables con investigaciones anteriores.

2.	**隆No eval煤es solo en una divisi贸n! Usa validaci贸n cruzada de 10 pliegues (folds) (no de 5 pliegues) y promedia los puntajes.**

    Se han visto informes que solo proporcionan resultados para una 煤nica divisi贸n de entrenamiento/prueba, por ejemplo, entrenar en los grupos 1-9, probar en el grupo 10 y reportar un 煤nico puntaje de precisi贸n. Aconsejamos en contra de esto. En su lugar, realiza validaci贸n cruzada de 10 pliegues usando los grupos proporcionados e informa el puntaje promedio.

  * **驴Por qu茅?**

    - No todos los grupos son tan "f谩ciles". Es decir, los modelos tienden a obtener puntajes mucho m谩s altos cuando se entrenan en los grupos 1-9 y se prueban en el grupo 10, comparado con (por ejemplo) entrenar en los grupos 2-10 y probar en el grupo 1. Por esta raz贸n, es importante evaluar tu modelo en cada una de las 10 divisiones e informar la precisi贸n promedio. De nuevo, tus resultados no ser谩n comparables con resultados anteriores en la literatura.




</details>

----------------




## 锔 **Pre-Processing**

<details>
    <summary> Expandir </summary>

* **Dataset UrbanSound8k**: Utilizado para la evaluaci贸n de modelos con 8,732 clips de audio a diferentes tasas de muestreo, reducidos a 16 kHz.

* **Segmentaci贸n de Audio**: Archivos de audio segmentados en 16,000 muestras con marcos superpuestos en un 50%. Esto podr铆a replicarse mediante el preprocesamiento de datos de audio para ajustarse a los requisitos de entrada del modelo.


</details>

----------------






##  **Arquitectura y Training**

<details>
    <summary> Expandir </summary>

* **Capas Convolucionales**: La experimentaci贸n mostr贸 un aumento en la precisi贸n con m谩s capas convolucionales hasta cuatro, despu茅s de lo cual la dimensi贸n del mapa de caracter铆sticas se minimiza. Esto sugiere que un modelo con hasta cuatro capas convolucionales es 贸ptimo para esta tarea.

* **Evaluaci贸n en Diferentes Longitudes de Audio**: El modelo se adapt贸 para varios tama帽os de entrada, logrando la mayor precisi贸n con entradas de 16,000 muestras. Esto enfatiza la importancia de considerar la longitud de entrada en el dise帽o de la arquitectura del modelo.


</details>

----------------




##  **Fine-Tuning y Mejoras**

<details>
    <summary> Expandir </summary>

* **Solapamiento de Ventanas y Tama帽o de Marco**: Se probaron diferentes configuraciones de solapamiento de ventanas y tama帽os de marcos de audio, resaltando la importancia de estos par谩metros en el rendimiento del modelo.

* **Mejoras en la Arquitectura**:

  - Reemplazar la ventana deslizante de Hamming por una rectangular para una posible mejora en la precisi贸n.

  - Aumentar el solapamiento de ventanas durante la segmentaci贸n de audio puede mejorar el rendimiento.

  - Inicializar la primera capa convolucional con un banco de filtros Gammatone y hacerla no entrenable para mejorar la precisi贸n.


</details>

----------------




##  **Optimizaci贸n**

<details>
    <summary> Expandir </summary>

* **Optimizaci贸n**: Se utiliz贸 el optimizador Adadelta con una tasa de aprendizaje predeterminada de 1.0, adaptando din谩micamente la tasa de aprendizaje durante la optimizaci贸n.

* **Agregaci贸n de Predicciones al Estilo de Conjunto**: Combinar predicciones de marcos de audio segmentados puede mejorar el rendimiento general de la clasificaci贸n.



</details>

----------------




##  **Conclusiones**

<details>
    <summary> Expandir </summary>

* **Eficiencia de la Arquitectura**: La CNN 1D propuesta, con tres a cinco capas convolucionales, aprende de manera eficiente representaciones de filtros directamente de la forma de onda de audio, superando a las CNNs 2D de 煤ltima generaci贸n utilizadas para la clasificaci贸n de sonidos ambientales en t茅rminos de precisi贸n y complejidad del modelo.

* **Reducci贸n de la Complejidad del Modelo**: A pesar de tener menos par谩metros que muchas arquitecturas de CNN 2D, la CNN 1D logra una precisi贸n media significativamente mayor, mostrando la eficiencia y efectividad del modelo.

* **Potencial para la Integraci贸n de Representaciones 1D y 2D**: La observaci贸n de que puede haber aspectos complementarios entre los filtros 1D (aprendidos directamente de las formas de onda de audio) y los filtros 2D (aprendidos de los espectrogramas) sugiere una direcci贸n futura de investigaci贸n. Integrar representaciones 1D y 2D podr铆a potencialmente mejorar el rendimiento de clasificaci贸n para ciertas clases de sonido.

* **Necesidad de m谩s Investigaci贸n**: El art铆culo indica la necesidad de investigar m谩s sobre los filtros ruidosos de las capas convolucionales intermedias sin frecuencias dominantes. Esto apunta a posibles mejoras en el modelo al refinar estos filtros.


</details>

----------------




## 锔 **C贸digo**

<details>
    <summary> Expandir </summary>

* []()
  

</details>

----------------



